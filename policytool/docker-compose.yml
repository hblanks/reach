version: '3.4'




x-airflow-image: &airflow-image
  160358319781.dkr.ecr.eu-west-1.amazonaws.com/uk.ac.wellcome/web-scraper:latest

x-airflow_env: &airflow-env
  AIRFLOW_HOME: /airflow

  # AIRFLOW_CONN_DIMENSIONS_DEFAULT: "https://${DIMENSIONS_USERNAME}:${DIMENSIONS_PASSWORD}@app.dimensions.ai/api/"

  # S3 prefix for all datalabs operators.
  # (in `core` because we must be in an existing section of the cfg)
  AIRFLOW__CORE__DATALABS_S3_PREFIX: "s3://datalabs-dev/airflow" # No trailing /!
  # AIRFLOW__CORE__DATALABS_ALTERYX_PREFIX: "s3://datalabs-staging/alteryx" # No trailing /!

  # dev creds encryption key, cf.
  # https://airflow.readthedocs.io/en/stable/howto/secure-connections.html
  # (but not used; everything's from env atm)
  AIRFLOW__CORE__FERNET_KEY: "${AIRFLOW_FERNET_KEY}"

  # Wait 20s to connect to PostgreSQL, in case it's coming up fresh.
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgresql://postgres:development@postgres:5432/airflow?connect_timeout=20"
  AIRFLOW__CELERY__BROKER_URL: "redis://redis:6379/0"
  AIRFLOW__CELERY__RESULT_BACKEND: "db+postgresql://postgres:development@postgres:5432/airflow_celery_results?connect_timeout=20"

  AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
  AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"

  # For local dev, also send task logs to stderr.
  # no longer needed once we're on current airflow
  # AIRFLOW__CORE__LOGGING_CONFIG_CLASS: "scraper.airflow.logging_config.CONSOLE_LOGGING_CONFIG"

  DATALABS_AIRFLOW_VERSION: "localdev"

  SENTRY_DSN: "${SENTRY_DSN}"
  DATABASE_URL: "postgresql://postgres:development@postgres:5432/wsf_scraping"
  RESOURCES_FILES: "/src/policytool/resources/"


x-airflow-volumes: &airflow-volumes
  - ./scraper/airflow/airflow.cfg:/airflow/airflow.cfg
  - ./scraper/airflow/initdb.sh:/airflow/initdb.sh
  - ./scraper:/src/policytool/scraper
  - ./pdf_parser:/src/policytool/pdf_parser
  - ./build/airflow.db:/airflow/db

# Restart airflow several times in case the DB wasn't present.
# (Yes, we could netcat, but postgres can accept TCP conns before
# accepting queries...so health checking is not so easy here.)
x-airflow-restart: &airflow-restart
  condition: on-failure
  delay: 2s
  max_attempts: 4
  window: 3s


services:
  postgres:
    image: postgres:11.2-alpine
    ports:
      - 127.0.0.1:5432:5432
    environment:
      POSTGRES_PASSWORD: development
    volumes:
      - ./build/airflow.db:/var/lib/postgresql/data
      - ./scraper/airflow/initdb:/docker-entrypoint-initdb.d

  redis:
    image: redis:5.0.3-alpine
    ports:
      - 127.0.0.1:6379:6379
    command:
      - redis-server
      - --appendonly
      - "yes"
    volumes:
      - ./build/airflow.redis:/data

  airflow-scheduler:
    image: *airflow-image
    environment:
      <<: *airflow-env
      POSTGRES_DSN: "postgresql://postgres:development@postgres:5432/airflow?connect_timeout=20"
    command:
      - /src/policytool/scraper/pg_isready.py
      - sh
      - "-cx"
      - "/airflow/initdb.sh && exec airflow scheduler"
    volumes: *airflow-volumes
    depends_on: ["postgres", "redis"]

  airflow-web:
    image: *airflow-image
    ports:
      - 127.0.0.1:8080:8080
    environment:
      <<: *airflow-env
      POSTGRES_DSN: "postgresql://postgres:development@postgres:5432/airflow?connect_timeout=20"
    command:
      # airflow webserver must be brought up only after the DB is
      # reliably serving connections, and after key parts of the DDL are
      # in place.
      # Thus pg_isready.py, and with a longer success-secs than
      # airflow-scheduler.
      - /src/policytool/scraper/pg_isready.py
      - "--timeout=30"
      - "--success-secs=8"  # allow extra time for initdb to get started
      - airflow
      - webserver
      - "-p"
      - "8080"
    volumes: *airflow-volumes
    depends_on: ["postgres", "redis"]

  airflow-worker:
    image: *airflow-image
    environment:
      <<: *airflow-env
      POSTGRES_DSN: "postgresql://postgres:development@postgres:5432/airflow?connect_timeout=20"
    command:
      - airflow
      - worker
    volumes: *airflow-volumes
    depends_on: ["postgres", "redis"]
